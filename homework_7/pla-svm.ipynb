{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.017, 0.0002, array([[-1.        ],\n",
      "       [-0.98176179],\n",
      "       [ 1.89013047]]))\n",
      "#####################################################\n",
      "0.253\n",
      "#####################################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4700aa64a7e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;31m# svm comparrison with N = 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[1;31m# returns value of 0.329, closest is 0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4700aa64a7e1>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_num, data_size, e_in, SVM)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mrepeats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0merror\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4700aa64a7e1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;31m# find all misclassified points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mreal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[0mrepeats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     \u001b[0mmisclassified\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4700aa64a7e1>\u001b[0m in \u001b[0;36mhypothesis\u001b[1;34m(self, point)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class PerceptronSVM:\n",
    "    def __init__(self,X_train, X_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        \n",
    "        self.w_vect = np.array([[0.,0.,0.]]).T\n",
    "        \n",
    "        self.point1 = [random.uniform(-1,1),random.uniform(-1,1)]\n",
    "        self.point2 = [random.uniform(-1,1),random.uniform(-1,1)]\n",
    "    \n",
    "    def target(self,point):\n",
    "        x, y = point[1], point[2]\n",
    "        x1,y1 = self.point1\n",
    "        x2,y2 = self.point2\n",
    "        \n",
    "        slope = (y2-y1)/(x2-x1)\n",
    "        \n",
    "        if y > slope * (x - x1) + y1: return 1\n",
    "        else: return -1\n",
    "\n",
    "\n",
    "    def hypothesis(self,point):\n",
    "        return np.sign(np.dot(point, self.w_vect))\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        misclassified = []\n",
    "        repeats = 0\n",
    "\n",
    "        while True:\n",
    "            for point in self.X_train:\n",
    "                # find all misclassified points\n",
    "                real = self.target(point)\n",
    "                if self.hypothesis(point) != real:\n",
    "                    repeats += 1\n",
    "                    misclassified.append([point, real])\n",
    "                # modify weights to classify correctly, we apply PLA only to separable data \n",
    "                # otherwise would have to use pocket algorithm\n",
    "            if not misclassified:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # choosing a random point to train the perceptron\n",
    "                point, y_n = random.choice(misclassified)\n",
    "                # w' = w + y*x \n",
    "                self.w_vect += y_n * np.array([point]).T\n",
    "                misclassified = []\n",
    "        return repeats\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        err = 0\n",
    "        for point in self.X_test:\n",
    "            if self.hypothesis(point) != self.target(point):\n",
    "                err += 1\n",
    "\n",
    "        return err / float(len(self.X_test))\n",
    "\n",
    "    \n",
    "def run(run_num,data_size, e_in = False, SVM = False):\n",
    "    supports = []\n",
    "    percentage_svm = 0\n",
    "    for i in range(run_num):\n",
    "        X_train = [[1.,random.uniform(-1,1),random.uniform(-1,1)] for i in range(data_size)]\n",
    "        \n",
    "        if e_in:\n",
    "            X_test = X_train\n",
    "\n",
    "        else:\n",
    "            X_test = [[1.,random.uniform(-1,1),random.uniform(-1,1)] for i in range(data_size)]\n",
    "\n",
    "        pla = PerceptronSVM(X_train, X_test)\n",
    "        \n",
    "        y_target = np.array([pla.target(point) for point in X_train])\n",
    "        test_target = np.array([pla.target(point) for point in X_test])\n",
    "        \n",
    "        repeats = pla.train()\n",
    "        error  = pla.test()\n",
    "\n",
    "        if SVM:\n",
    "            skip = 0\n",
    "            support_error = 0\n",
    "\n",
    "            # we have a problem if either of our y's are homogenous in class, hence need to check\n",
    "            # if all elements are the same, we skip the fitting.\n",
    "            if np.array_equal(y_target,np.ones(data_size)) or np.array_equal(y_target, -1*np.ones(data_size)): \n",
    "                skip +=1\n",
    "                continue\n",
    "                \n",
    "            model = SVC(kernel = 'linear',C = 658758587)\n",
    "            \n",
    "            # we do not need the ones in the training data.\n",
    "            adapted_X = np.delete(np.array(X_train), 0, 1)\n",
    "          \n",
    "            model.fit(adapted_X,y_target)\n",
    "            \n",
    "            adapted_test = np.delete(X_test,0,1)\n",
    "            predict = model.predict(adapted_test)\n",
    "            \n",
    "            # error of SVM\n",
    "            support_er = len(test_target[test_target != predict]) / float(len(test_target))\n",
    "#             print(\"go {}, errors {} vs {}\".format(str(i),str(support_er),str(error)))\n",
    "            if support_er < error:\n",
    "                percentage_svm += 1\n",
    "            \n",
    "    \n",
    "    if not SVM:\n",
    "        return repeats / float(run_num), error / float(run_num), pla.w_vect\n",
    "    else:\n",
    "        return percentage_svm / float(run_num)\n",
    "if __name__ == \"__main__\":\n",
    "    # pla\n",
    "    print(run(run_num = 1000, data_size = 10))\n",
    "    # returns the out-error of 0.0001 and w = (0,1.2398,1.01533)\n",
    "    print(\"#####################################################\")\n",
    "    \n",
    "    # svm comparrison with N = 10\n",
    "    print(run(run_num = 1000, data_size = 10, SVM = True))\n",
    "    # returns 0.263 which is closest to 0.3\n",
    "    \n",
    "    print(\"#####################################################\")\n",
    "    \n",
    "    # svm comparrison with N = 100\n",
    "    print(run(run_num=1000, data_size= 100, SVM = True))\n",
    "    # returns value of 0.329, closest is 0.3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
