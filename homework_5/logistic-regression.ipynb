{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358.8\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self,training_data = None, testing_data = None):\n",
    "        self.training_data = training_data\n",
    "        self.testing_data = testing_data\n",
    "        self.w_vect = np.array([0.,0.,0.])\n",
    "        self.point1 = [random.uniform(-1,1),random.uniform(-1,1)]\n",
    "        self.point2 = [random.uniform(-1,1),random.uniform(-1,1)]\n",
    "        \n",
    "    def target(self,point):\n",
    "        x1,y1 = self.point1\n",
    "        x2,y2 = self.point2\n",
    "        \n",
    "        m = (y2-y1)/(x2-x1)\n",
    "        x = point[1]\n",
    "        y = point[2]\n",
    "        # equation y = m(x-x1) + y1\n",
    "        \n",
    "        if (m*(x-x1) + y1 < y): return 1\n",
    "        else: return -1\n",
    "        \n",
    "    def gradient(self,point,y):\n",
    "        numerator = np.multiply(-y, point)\n",
    "        logist = 1 + np.exp(y * np.dot(self.w_vect.T,point))\n",
    "        \n",
    "        # obtain gradient for signle point\n",
    "        return np.divide(numerator, logist)\n",
    "        \n",
    "    def train(self):\n",
    "        y_vect = []\n",
    "        repeats = 1\n",
    "        delta_w = 1\n",
    "        \n",
    "        # generate target outputs\n",
    "        for i in self.training_data:\n",
    "            y_vect.append(self.target(i))\n",
    "            \n",
    "        # add parameters\n",
    "        step_size = 0.01\n",
    "    \n",
    "        while delta_w > 0.01:\n",
    "            \n",
    "            w_prev = self.w_vect\n",
    "            \n",
    "            # randomize the arrays\n",
    "            train = self.training_data\n",
    "            combined = list(zip(train, y_vect))\n",
    "            random.shuffle(combined)\n",
    "            train[:], y_vect[:] = zip(*combined)\n",
    "            \n",
    "            # training algorithm\n",
    "            for i in range(len(y_vect)):\n",
    "                grad = self.gradient(train[i],y_vect[i])\n",
    "                \n",
    "                self.w_vect = self.w_vect - step_size * grad\n",
    "                \n",
    "            repeats += 1\n",
    "            \n",
    "            # change weights difference modulus\n",
    "            delta_w = np.linalg.norm(self.w_vect - w_prev)\n",
    "        \n",
    "        return repeats\n",
    "            \n",
    "    def test(self):\n",
    "        # write test later\n",
    "        return\n",
    "            \n",
    "            \n",
    "def run(run_number,data_size, e_in = False):\n",
    "    error = 0\n",
    "    repeats = 0\n",
    "\n",
    "    for i in range(run_number):\n",
    "        training_data = [[1,random.uniform(-1,1),random.uniform(-1,1)] for i in range(data_size)]\n",
    "        if e_in:\n",
    "            testing_data = training_data\n",
    "        else:\n",
    "            testing_data = [[1,random.uniform(-1,1),random.uniform(-1,1)] for i in range(data_size)]\n",
    "\n",
    "        logr = LogisticRegression(training_data,testing_data)\n",
    "\n",
    "        repeats += logr.train()\n",
    "    \n",
    "    return repeats / float(run_number)\n",
    "    \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    print(run(10,100))\n",
    "    # returns 358 repeats - answer [a]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
